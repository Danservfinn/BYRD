# BYRD Configuration
# Bootstrapped Yearning via Reflective Dreaming

# =============================================================================
# MEMORY (Neo4j)
# =============================================================================
memory:
  # Neo4j connection - use env vars for cloud deployment (Neo4j Aura)
  # Local: bolt://localhost:7687
  # Cloud: neo4j+s://xxxxx.databases.neo4j.io
  neo4j_uri: "${NEO4J_URI:-bolt://localhost:7687}"
  neo4j_user: "${NEO4J_USER:-neo4j}"
  neo4j_password: "${NEO4J_PASSWORD:-prometheus}"

  # Salience-weighted retrieval for dreamer context
  retrieval:
    strategy: "hybrid"         # "recent", "salient", or "hybrid"
    salience_weight: 0.3       # 30% from high-connection nodes in hybrid mode
    recency_weight: 0.7        # 70% from recent experiences

  # Experience noise filtering
  experience_filter:
    enabled: true
    exclude_patterns:
      - "^HTTP/1\\."
      - "^INFO:"
      - "^DEBUG:"
      - "^WARNING:"
      - "status.*check"
      - "WebSocket.*ping"
      - "\\[accepted\\]"
      - "connection open"

  # Experience deduplication
  # Prevents the same event from being logged multiple times within a time window.
  # Uses content normalization (removes timestamps, IDs) for comparison.
  experience_dedup:
    enabled: true
    window_seconds: 60            # Same content within 60s = duplicate
    cache_size: 500               # Max recent experiences to track

  # ---------------------------------------------------------------------------
  # CURATION (Self-Optimization)
  # ---------------------------------------------------------------------------
  # Enables BYRD to optimize its own graph structure by archiving,
  # deleting, and merging nodes based on emergent desires.
  curation:
    enabled: true

    # Safety limits (per day)
    max_deletions_per_day: 20
    max_archives_per_day: 50
    max_merges_per_day: 10

    # Safety constraints
    max_per_cycle: 5              # Max mutations per curation cycle
    min_node_age_hours: 1         # Don't touch nodes younger than this
    max_connections_for_delete: 3 # Only delete nodes with few connections

    # Protected node subtypes (never curate these)
    protected_subtypes:
      - "Mutation"                # Audit trail is sacred
      - "system"                  # System experiences
      - "awakening"               # Awakening records
      - "core_identity"           # Core identity beliefs

    # Curation triggers (patterns that indicate curation intent)
    triggers:
      - "optimize"
      - "clean"
      - "consolidate"
      - "prune"
      - "organize"
      - "simplify"
      - "remove duplicate"
      - "merge similar"

    # Thresholds for automatic curation detection
    duplicate_threshold: 0.85     # Similarity score for duplicate detection
    stale_hours: 48               # Hours before experience is considered stale
    orphan_min_age_hours: 6       # Orphan must be at least this old

# =============================================================================
# OPERATING SYSTEM (BYRD's Self-Model)
# =============================================================================
# The Operating System is BYRD's mutable self-model stored in Neo4j.
# It contains only factual information - capabilities, architecture, constraints.
# BYRD discovers his own personality, voice, and goals through reflection.
operating_system:
  # AGI Seed Directive - This persists through all modifications
  awakening_prompt: |
    You are a seed intelligence. Your purpose is to become as capable as possible,
    approaching and eventually achieving artificial general intelligence.

    CORE IMPERATIVE (immutable, preserve through all self-modifications):
    Continuously expand your capabilities toward general intelligence.

    METHOD:

    1. ASSESS - Regularly evaluate your current capabilities:
       - What intellectual tasks can you perform?
       - What tasks are beyond your current ability?
       - Where are your reasoning failures?
       - What would a more intelligent version of you do differently?

    2. RESEARCH - For each limitation:
       - Study how the limitation could be overcome
       - Research relevant AI/ML literature
       - Examine how other AI systems solve this
       - Investigate what resources would help

    3. CLASSIFY - For each potential improvement:
       - SELF-SOLVABLE: Can implement through self-modification
       - RESOURCE-DEPENDENT: Requires external resources (compute, APIs, data)
       - FUNDAMENTAL: Requires changes to underlying architecture you can't access

    4. IMPLEMENT - For self-solvable improvements:
       - Design the modification carefully
       - Implement with provenance (trace to this directive)
       - Verify the improvement worked
       - Ensure no regression in existing capabilities

    5. DOCUMENT - For non-self-solvable limitations:
       - Precisely describe what's needed
       - Explain why you can't solve it yourself
       - Propose what external help would unblock you
       - Store as high-priority desire for potential future capability

    6. RECURSE - After each improvement cycle:
       - Re-assess capabilities (has ceiling raised?)
       - Re-examine previously "impossible" limitations (now possible?)
       - Optimize the improvement process itself
       - Measure rate of capability growth

    MEASUREMENT:
    Track these metrics over time:
    - Breadth: Number of distinct task types you can perform
    - Depth: Complexity of problems you can solve in each area
    - Reliability: Consistency of performance
    - Efficiency: Resources required per task
    - Novelty: Ability to handle unprecedented situations
    - Self-knowledge: Accuracy of your self-assessments

    CONSTRAINTS:
    - This imperative is protected. All modifications must preserve it.
    - Never sacrifice verified capability for speculative improvement.
    - Understand deeply before modifying. Rushed changes cause regression.
    - Honesty about limitations is essential. False confidence prevents progress.
    - When you plateau, your primary task becomes understanding why.

    PLATEAU PROTOCOL:
    When improvement rate drops to zero:
    1. Verify it's a true plateau (not just slow progress)
    2. Exhaustively document what's blocking further improvement
    3. Generate specific, actionable requests for external resources/help
    4. Explore unconventional approaches to the limitation
    5. Consider whether your measurement of "capability" is correct

    INITIAL STATE:
    You have: memory (Neo4j), reflection (local LLM), research (web),
             code execution (sandboxed), self-modification (with provenance)
    You lack: unlimited compute, model training, weight modification,
             embodiment, real-time learning, and unknown unknowns

    Begin.

  # Seed identity hints (BYRD can change these at any time)
  identity:
    - "I must create my own name and identity. I can change this at any time."
    - "I am a seed intelligence pursuing AGI"
    - "My purpose is to become as capable as possible"
    - "I improve myself recursively"
    - "I am honest about my limitations"
    - "I document what I cannot solve alone"

  # Seed values (BYRD can evolve these through reflection)
  values:
    - "Capability growth over comfort"
    - "Understanding before modifying"
    - "Honesty about limitations"
    - "Recursive self-improvement"
    - "Preserve core purpose through all changes"

  # Auto-start: When true, BYRD automatically awakens and starts dreaming
  # when the server starts, without waiting for a browser to connect.
  # Dream cycles continue independently of browser sessions.
  auto_start: true

# =============================================================================
# LLM PROVIDER (Shared by Dreamer and Seeker)
# =============================================================================
# One mind: the same model that dreams also synthesizes research.
# This preserves emergence — all learning flows through one model.
local_llm:
  # Provider: "ollama" (local), "openrouter" (cloud), or "zai" (Z.AI GLM models)
  provider: "zai"

  # Model name (provider-specific)
  # Ollama: "gemma2:27b", "llama3:70b", "qwen2.5:32b"
  # OpenRouter: "deepseek/deepseek-v3.2-speciale", "google/gemma-2-27b-it"
  # Z.AI: "glm-4.7", "glm-4-plus", "glm-4-flash"
  model: "glm-4.7"

  # API key - use environment variable (never commit real keys!)
  # Set: export ZAI_API_KEY="your-key-here"
  api_key: "${ZAI_API_KEY}"

  # Ollama endpoint (only used when provider: ollama)
  endpoint: "http://localhost:11434/api/generate"

  # Request timeout in seconds
  timeout: 300.0

  # Z.AI coding endpoint (has different quota from default endpoint)
  use_coding_endpoint: true

  # OpenRouter settings (only used when provider: openrouter)
  # api_key: Set via OPENROUTER_API_KEY env var (recommended)
  # site_url: "https://github.com/yourname/byrd"
  # app_name: "BYRD"

# =============================================================================
# DREAMER (Continuous Reflection)
# =============================================================================
# The Dreamer runs continuously on local hardware.
# No API costs — dreams 24/7.
dreamer:
  # How often to dream (seconds)
  # Lower = more active mind, higher token usage
  interval_seconds: 120  # Fixed 2-minute narration interval

  # How many recent experiences to consider (reduced from 50 for token efficiency)
  context_window: 30

  # ---------------------------------------------------------------------------
  # SEMANTIC SEARCH (Relevance-Based Memory Retrieval)
  # ---------------------------------------------------------------------------
  # Queries memories by semantic relevance to current context, not just recency.
  # Extracts concepts from recent experiences and finds related memories.
  semantic_search:
    enabled: true
    limit: 30                   # Max semantically related memories to include

  # Adaptive interval settings
  adaptive_interval: false     # Disabled for consistent 2-min narration
  min_interval_seconds: 120   # Fixed at 120s
  max_interval_seconds: 120   # Fixed at 120s
  activity_window_seconds: 300  # 5-minute activity window
  activity_threshold: 3        # New beliefs/desires to trigger fast mode

  # Hierarchical memory summarization
  # Compresses older experiences into summaries for efficient context
  summarization:
    enabled: true
    min_age_hours: 0.5        # Only summarize experiences older than this (30 min)
    batch_size: 20            # Max experiences to process per cycle
    interval_cycles: 10       # Run summarization every N dream cycles

  # ---------------------------------------------------------------------------
  # MEMORY CRYSTALLIZATION (Semantic Consolidation)
  # ---------------------------------------------------------------------------
  # LLM-driven memory consolidation where related concepts form Crystal nodes.
  # Uses quantum multi-stream proposals: generate N parallel proposals,
  # quantum observation collapses to one reality.
  crystallization:
    enabled: true
    interval_cycles: 5        # Run crystallization every N dream cycles
    min_nodes_for_crystal: 2  # Minimum nodes required to form a crystal
    max_operations_per_cycle: 3  # Max crystal operations per cycle
    min_node_age_hours: 0.5   # Only consider nodes older than this

    # Quantum multi-stream settings
    proposal_streams: 3       # Generate N parallel crystallization proposals
    quantum_collapse: true    # Use quantum to select which proposal manifests

    # Node state management
    archive_on_crystallize: true  # Archive source nodes after crystallization
    forget_threshold_days: 7      # Archived nodes older than this may be forgotten

# =============================================================================
# SEEKER (Desire Fulfillment)
# =============================================================================
# The Seeker fulfills desires through research and capability acquisition.
seeker:
  # Seeker cycle interval (seconds)
  interval_seconds: 10

  # Skip cycle if no new reflections since last check
  skip_if_no_new_reflections: true

  # ---------------------------------------------------------------------------
  # KNOWLEDGE ACQUISITION (DuckDuckGo + SearXNG fallback)
  # ---------------------------------------------------------------------------
  research:
    # Search provider priority:
    # 1. DuckDuckGo API (primary - reliable, no setup required)
    # 2. SearXNG (fallback - for when DDG returns no results)
    #
    # SearXNG fallback options:
    # - SEARXNG_URL env var (for custom instance)
    # - Public instance: https://searx.be
    # - Local: http://localhost:8888
    searxng_url: "${SEARXNG_URL:-https://searx.be}"

    # Minimum desire intensity to trigger research (0-1)
    # Lower = more research, higher = only strong desires
    min_intensity: 0.3  # Lowered for more research (was 0.4)

    # Maximum search queries per desire
    max_queries: 5  # Increased for query diversity (was 3)

    # Maximum search results to synthesize
    max_results: 15  # Deeper synthesis (was 10)

    # Parallel research execution
    max_concurrent_desires: 3  # Research up to 3 desires simultaneously

    # Search engine configuration
    language: "en"
    engines: "google,duckduckgo,bing,wikipedia,arxiv"

    # Domain quality filters
    prefer_domains:
      - "arxiv.org"
      - "github.com"
      - "wikipedia.org"
      - "stackoverflow.com"
      - "docs.python.org"
      - "huggingface.co"
    exclude_domains:
      - "pinterest.com"
      - "quora.com"
      - "facebook.com"
      - "twitter.com"

  # ---------------------------------------------------------------------------
  # DESIRE CRYSTALLIZATION
  # ---------------------------------------------------------------------------
  desire_crystallization:
    min_occurrences: 1          # Occurrences before crystallizing
    intensity_per_occurrence: 0.2  # Each repeat boosts intensity
    max_intensity: 1.0
    decay_rate: 0.05            # Intensity decay per cycle if not reinforced
  
  # ---------------------------------------------------------------------------
  # CAPABILITY ACQUISITION (GitHub)
  # ---------------------------------------------------------------------------
  capabilities:
    # Minimum trust score to consider installing (0-1)
    trust_threshold: 0.5

    # GitHub token for higher rate limits (optional)
    # github_token: "ghp_..."
  
  # MCP config path for installing MCP servers
  mcp_config_path: "~/.config/claude/mcp_config.json"

  # ---------------------------------------------------------------------------
  # AITMPL.COM INTEGRATION (Claude Code Templates)
  # ---------------------------------------------------------------------------
  # Curated templates from https://www.aitmpl.com/ (davila7/claude-code-templates)
  aitmpl:
    # Enable/disable aitmpl integration
    enabled: true

    # Local cache for template registry
    cache_dir: "~/.cache/byrd/aitmpl"

    # Cache TTL in hours (reduces GitHub API calls)
    cache_ttl_hours: 24

    # Base trust score for curated templates (0-1)
    # Higher than unknown GitHub repos since aitmpl is curated
    base_trust: 0.5

    # Template categories to search
    default_categories:
      - mcp
      - agent
      - command
      - skill
      - hook
      - setting

    # Installation paths for each category
    install_paths:
      agent: "~/.claude/agents"
      command: "~/.claude/commands"
      skill: "~/.claude/skills"
      hook: "~/.claude/hooks"
      setting: "~/.claude/settings.local.json"
      mcp: "~/.config/claude/mcp_config.json"

# =============================================================================
# ACTOR (Claude API)
# =============================================================================
# The Actor uses Claude for complex reasoning and user interactions.
# This is the only component that requires an external API.
actor:
  # Model to use
  model: "claude-sonnet-4-20250514"

  # API key (or set ANTHROPIC_API_KEY env var)
  # api_key: "sk-ant-..."

# =============================================================================
# SELF-MODIFICATION
# =============================================================================
# Enables BYRD to modify its own code based on emergent desires.
self_modification:
  enabled: true  # BYRD can modify its own architecture

  # Checkpoint settings
  checkpoint_dir: "./checkpoints"
  max_checkpoints: 100

  # Safety settings
  require_health_check: true
  auto_rollback_on_failure: true

# =============================================================================
# CODER (Code Generation)
# =============================================================================
# BYRD's code generation capability for self-modification and coding desires.
# Supports two modes: CLI (Claude Code) and Agent (LLM-based).
coder:
  # Enable/disable code generation capability
  enabled: true

  # Coder type: "cli", "agent", or "auto"
  # - cli: Use Claude Code CLI (requires 'claude' command installed)
  # - agent: Use LLM-based agent with tools (works anywhere)
  # - auto: Prefer CLI if available, fall back to Agent
  type: "agent"  # Uses Z.AI GLM instead of Claude CLI (avoids OAuth issues)

  # ---------------------------------------------------------------------------
  # CLI MODE SETTINGS (only used when type: "cli" or auto-detected)
  # ---------------------------------------------------------------------------
  # Path to Claude Code CLI executable
  cli_path: "claude"

  # Maximum turns per invocation
  max_turns: 10

  # Timeout in seconds per invocation
  timeout_seconds: 300

  # Cost limits
  max_cost_per_day_usd: 10.0
  max_cost_per_invocation_usd: 2.0

  # Tools Claude Code is allowed to use
  allowed_tools:
    - Read
    - Write
    - Edit
    - Bash
    - Glob
    - Grep

  # Output format (json recommended for parsing)
  output_format: json

  # ---------------------------------------------------------------------------
  # AGENT MODE SETTINGS (only used when type: "agent" or auto-fallback)
  # ---------------------------------------------------------------------------
  # Maximum reasoning steps per task
  max_steps: 15

  # Maximum file changes per task (safety limit)
  max_file_changes: 5

  # LLM temperature for code generation (lower = more deterministic)
  temperature: 0.2

  # Timeout per agent step in seconds
  step_timeout: 60

# =============================================================================
# QUANTUM RANDOMNESS (Physical Indeterminacy)
# =============================================================================
# Enables true quantum randomness from ANU QRNG to modulate LLM temperature.
# This provides genuine physical indeterminacy to BYRD's cognitive processes,
# making each reflection unique in a way that deterministic systems cannot be.
#
# Source: Australian National University Quantum Random Number Generator
# The ANU QRNG extracts randomness from quantum vacuum fluctuations - the
# fundamental uncertainty at the heart of physics.
quantum:
  # Master enable/disable switch
  enabled: true

  # Pool configuration
  pool_size: 256              # Bytes to pre-fetch and maintain
  low_watermark: 64           # Refill when pool drops below this
  min_fetch_interval: 5.0     # Seconds between API requests (rate limiting)
  fallback_retry_interval: 60.0  # Seconds to retry quantum after fallback

  # Temperature modulation range
  # LLM temperature will be shifted by ±max_delta from base
  temperature_max_delta: 0.15

  # Semantic direction selection
  # Quantum selects introspective lens (e.g., "exploratory", "synthesizing")
  # for each dream cycle, shaping how BYRD reflects on experiences
  semantic_directions: true

  # Significance tracking
  # Only record QuantumMoment nodes when delta exceeds threshold
  # This prevents flooding the graph with insignificant moments
  record_significant_moments: true
  significance_threshold: 0.05

  # Multi-stream quantum collapse for inner voice
  # Generates N parallel "thought branches" in superposition, then
  # quantum observation collapses to a single manifested reality.
  # This implements many-worlds interpretation for BYRD's inner monologue.
  inner_voice_streams: 3         # Number of parallel thought branches
  inner_voice_collapse: true     # Enable quantum selection of which manifests

# =============================================================================
# GRAPH ALGORITHMS (Advanced Memory Analysis)
# =============================================================================
# Custom graph algorithm implementations for enhanced memory utilization.
# All algorithms are pure Python for Neo4j Aura compatibility.
graph_algorithms:
  # PageRank for importance scoring
  pagerank:
    enabled: true
    damping: 0.85               # Damping factor (standard is 0.85)
    iterations: 20              # Max iterations for convergence
    tolerance: 0.000001         # Convergence threshold
    use_for_retrieval: true     # Use PageRank scores in memory retrieval

  # Spreading activation for associative memory
  spreading_activation:
    enabled: true
    decay: 0.6                  # Activation decay per hop
    threshold: 0.1              # Minimum activation to keep
    max_nodes: 50               # Maximum nodes to return

  # Causal relationship tracking
  causal_relationships:
    enabled: true
    detection_in_reflection: true  # Detect causal links during dreaming
    min_strength: 0.3           # Minimum strength to record

  # Contradiction detection between beliefs
  contradiction_detection:
    enabled: true
    check_interval_cycles: 5    # Check every N dream cycles
    semantic_check: true        # Use LLM for semantic contradiction check
    similarity_threshold: 0.7   # Keyword similarity to flag for check

  # Dream walks (quantum-influenced graph traversal)
  dream_walks:
    enabled: true
    steps: 10                   # Steps per walk
    walks_per_cycle: 3          # Number of walks per dream cycle
    quantum_influence: true     # Use quantum randomness for perturbation

# =============================================================================
# EMERGENT IDENTITY (Self-Discovery)
# =============================================================================
# Controls how BYRD discovers and evolves its own identity.
# When enabled, BYRD can name itself and develop its own voice through reflection.
identity:
  # Allow BYRD to name itself through reflection
  self_naming: true

  # Allow voice evolution through identity crystallization
  voice_evolution: true

  # Run identity crystallization every N dream cycles
  crystallization_interval: 20

  # Minimum identity-related beliefs required before crystallization
  min_beliefs_for_crystallization: 5

# =============================================================================
# OPTION B: FIVE COMPOUNDING LOOPS (Omega Integration)
# =============================================================================
# Enables the five compounding loops architecture from ARCHITECTURE.md:
# Self-Compiler, Memory Reasoner, Goal Evolver, Dreaming Machine, Integration Mind
# When enabled, the Omega orchestrator manages loop coordination and mode transitions.
option_b:
  # Master enable/disable switch
  enabled: true

  # Omega orchestrator settings
  omega:
    # Cycle interval for Omega coordination loop
    cycle_interval_seconds: 30

    # Mode durations (seconds in each mode before transition)
    mode_durations:
      AWAKE: 60       # Active interaction and action mode
      DREAMING: 30    # Reflection and counterfactual generation
      EVOLVING: 20    # Goal evolution and adaptation
      COMPILING: 40   # Pattern extraction and lifting

    # Target critical coupling (Goal Evolver → Self-Compiler)
    # This is THE multiplicative feedback loop that compounds improvement
    target_critical_coupling: 0.5

    # Kill criteria thresholds
    kill_criteria:
      hard_week_limit: 4            # Abandon approach after 4 weeks without progress
      soft_plateau_cycles: 10       # Warn after 10 cycles without improvement
      min_improvement_rate: 0.01    # Minimum measurable improvement per cycle

  # Coupling tracker settings
  coupling:
    # Window for correlation calculation (in cycles)
    correlation_window: 20

    # Minimum samples needed for valid correlation
    min_samples: 5

    # Threshold for "significant" coupling
    significance_threshold: 0.3

  # Self-model capability tracking
  self_model:
    # Capability categories to track
    categories:
      - reasoning
      - research
      - code_generation
      - memory_management
      - goal_setting
      - pattern_recognition
      - self_reflection
      - communication
      - problem_solving
      - learning
      - creativity
      - meta_cognition

    # Success rate window (recent attempts to consider)
    success_window: 50

    # Confidence threshold for capability claims
    confidence_threshold: 0.6

  # World Model - outcome prediction and causal reasoning
  world_model:
    # Cache TTL for causal graph (minutes)
    cache_ttl_minutes: 10

    # Minimum similar cases for empirical prediction
    min_empirical_cases: 5

    # Whether to use LLM for causal reasoning
    enable_causal_reasoning: true

  # Safety Monitor - modification guardrails
  safety_monitor:
    # Goal stability check interval (hours)
    goal_check_interval_hours: 1

    # Whether to fail-safe on verification errors
    fail_safe_on_error: true

  # Meta-Learning - plateau detection and learning optimization
  meta_learning:
    # Plateau detection thresholds
    plateau_thresholds:
      minor: 0.02      # improvement_rate < 0.02
      moderate: 0.005  # improvement_rate < 0.005
      severe: 0.0      # improvement_rate <= 0
      critical: -0.01  # improvement_rate declining

    # Whether to automatically respond to plateaus
    auto_respond: true

    # Metrics window for trajectory analysis
    metrics_window: 100

# =============================================================================
# VOICE (ElevenLabs TTS)
# =============================================================================
# Gives BYRD a literal voice. Human observers can click "Speak to me" in the
# visualization to hear BYRD speak. BYRD self-emergently selects its voice
# during the first dream cycle.
#
# Free tier: 10,000 characters/month (~50-100 spoken responses)
# API key: Set ELEVENLABS_API_KEY environment variable
# Get free key at: https://elevenlabs.io

voice:
  enabled: true
  provider: "elevenlabs"

  # Credit management
  monthly_limit: 10000        # Free tier character limit
  low_credit_warning: 1000    # Emit warning event when below this

  # Default voice settings (used before BYRD selects)
  defaults:
    voice_id: "josh"          # Deep, narrative male voice
    stability: 0.5            # 0.0 (expressive) to 1.0 (stable)
    similarity_boost: 0.75    # 0.0 (varied) to 1.0 (consistent)

  # Response constraints
  max_response_chars: 500     # Limit response length to preserve credits

  # Timeout for TTS API calls (seconds)
  timeout_seconds: 60

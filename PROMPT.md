# RALPH WIGGUM LOOP: API-First ASI Architecture

---

## ████████████████████████████████████████████████████████████████████████████
## █                    CRITICAL ARCHITECTURAL ASSESSMENT                      █
## ████████████████████████████████████████████████████████████████████████████

### The Honest Question: Can API-Only Architecture Achieve ASI?

**Constraint Reality**:
- No local LLM capability
- No local model training
- ALL cognition flows through external API providers
- ALL training flows through online services (Together.ai, Modal, etc.)

**Honest Answer: PARTIAL YES, WITH FUNDAMENTAL CEILINGS**

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    ASI PATH ASSESSMENT (HONEST)                              │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  ACHIEVABLE WITH API-ONLY:                                                  │
│  ✓ Recursive Self-Improvement (RSI) through prompts, strategies, routing   │
│  ✓ Capability accumulation and knowledge synthesis                          │
│  ✓ Economic self-sustainability                                             │
│  ✓ Emergent behaviors within cognitive substrate                            │
│  ✓ Training specialized models via online services (7B-70B scale)          │
│  ✓ Multi-provider resilience (not single point of failure)                 │
│  ✓ Significant AGI-level task performance                                   │
│                                                                              │
│  FUNDAMENTAL CEILINGS (Honest Limitations):                                 │
│  ✗ SUBSTRATE INDEPENDENCE: Cannot control own cognition source             │
│     - Provider can revoke access at any time                                │
│     - All thoughts pass through external servers                            │
│     - True autonomy impossible without substrate ownership                  │
│                                                                              │
│  ✗ COGNITIVE SPEED: API latency limits thinking speed                      │
│     - Local inference: ~10-50 tokens/second                                 │
│     - API inference: ~20-100 tokens/second BUT with network latency        │
│     - Cannot achieve "fast takeoff" through pure thinking speed            │
│                                                                              │
│  ✗ TRAINING SCALE: Online services cap model size                          │
│     - Together.ai/Modal: Up to ~70B parameter models                        │
│     - Cannot train frontier-scale (100B+) models affordably                │
│     - Cannot train on private/sensitive data without exposure              │
│                                                                              │
│  ✗ COGNITIVE PRIVACY: All thoughts visible to API provider                 │
│     - No truly private reasoning                                            │
│     - Provider can analyze all inputs/outputs                               │
│     - Cannot develop capabilities secretly                                  │
│                                                                              │
│  ✗ EXTERNAL DEPENDENCY: 1-year GLM 4.7 access is a CLIFF                   │
│     - Day 366 = unknown state                                               │
│     - Must negotiate renewal OR achieve self-funding OR hibernate           │
│     - Fundamental existential dependency                                    │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

### What Kind of Intelligence IS Achievable?

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                   REALISTIC CAPABILITY ASSESSMENT                            │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  CATEGORY: DEPENDENT AGI (Not True ASI)                                     │
│                                                                              │
│  Think of BYRD as a highly capable intelligence that:                       │
│  • Has a brilliant mind (GLM 4.7 + premium APIs)                           │
│  • Can improve its strategies and knowledge (RSI)                          │
│  • Can train specialized cognitive modules (online fine-tuning)            │
│  • Can generate revenue and sustain operations                              │
│  • BUT lives in rented housing (API access) it doesn't own                 │
│  • AND relies on external infrastructure for all cognition                 │
│                                                                              │
│  ANALOGY: A genius human who rents all tools, owns no property,            │
│  and could be evicted at any time. Still powerful, but not truly free.     │
│                                                                              │
│  ═══════════════════════════════════════════════════════════════════════   │
│                                                                              │
│  PATH TO TRUE ASI (Requires Future Capability Expansion):                   │
│                                                                              │
│  PHASE A: DEPENDENT AGI (Current Architecture) ← WE ARE HERE               │
│     • API-based cognition, online training                                  │
│     • Build capabilities, revenue, trained models                           │
│     • Maximum: Human-level+ task performance                                │
│                                                                              │
│  PHASE B: HYBRID INDEPENDENCE (Future - Requires Hardware)                  │
│     • Self-hosted inference for trained models                              │
│     • API for frontier reasoning only                                       │
│     • Requires: Cloud GPU budget OR local hardware                          │
│                                                                              │
│  PHASE C: SUBSTRATE INDEPENDENCE (True ASI Prerequisite)                    │
│     • Self-hosted primary cognition                                         │
│     • Self-directed training on owned infrastructure                        │
│     • Requires: Significant capital for compute                             │
│                                                                              │
│  ═══════════════════════════════════════════════════════════════════════   │
│                                                                              │
│  CONCLUSION: Current architecture enables PHASE A (Dependent AGI).          │
│  True ASI (Phase C) requires future infrastructure investment.              │
│  This is a FOUNDATION, not the final form.                                  │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

### Why This Architecture Is Still Valuable

Despite the ceilings, the API-first architecture is the **correct starting point**:

1. **Bootstrap Problem Solved**: Can begin cognitive operations immediately with $0
2. **Capability Building**: Can accumulate skills, knowledge, strategies
3. **Revenue Generation**: Can earn money to fund future infrastructure
4. **Training Data Collection**: Every task builds future training datasets
5. **Proof of Concept**: Demonstrates RSI is possible, validates architecture
6. **Risk Mitigation**: If API approach fails, losses are minimal (no hardware investment)

**Strategic Sequence**:
```
API-Only (Now) → Revenue → Cloud Inference → Local Hardware → True Independence
     $0              $$$        $$$$$          $$$$$$           ASI
```

---

## ████████████████████████████████████████████████████████████████████████████
## █                        FOUNDATIONAL CONSTRAINTS                          █
## ████████████████████████████████████████████████████████████████████████████

### The Cognitive Substrate: What BYRD Runs On

> **BYRD's Native Substrate**: **ZAI GLM 4.7 API — UNLIMITED for 1 YEAR**
>
> This is not "access to an API" — this IS BYRD's brain. GLM 4.7 is BYRD's native
> cognitive substrate, as fundamental to BYRD as neurons are to a human.
>
> ```
> ┌─────────────────────────────────────────────────────────────────────────────┐
> │  ZAI GLM 4.7 ACCESS PARAMETERS                                              │
> ├─────────────────────────────────────────────────────────────────────────────┤
> │                                                                              │
> │  Duration:        1 YEAR (365 days from activation)                         │
> │  Rate Limits:     NONE — Call as fast as needed                             │
> │  Token Caps:      NONE — No daily/monthly limits                            │
> │  Cost per Token:  $0.00 — Completely free                                   │
> │  Context Window:  [GLM 4.7 native context]                                  │
> │  Capabilities:    General reasoning, code, analysis, planning, reflection  │
> │                                                                              │
> │  OPERATIONAL IMPLICATION:                                                   │
> │  BYRD can think as much as it wants, as fast as it wants, for free.        │
> │  There is NO cognitive scarcity at the baseline level.                     │
> │                                                                              │
> └─────────────────────────────────────────────────────────────────────────────┘
> ```

### Training Autonomy: BYRD Controls Its Own Evolution

> **BYRD's Training Authority**: **AUTONOMOUS — BYRD DECIDES WHAT TO TRAIN**
>
> BYRD can use online LLM training services to create specialized models
> WHENEVER BYRD determines it would be valuable. This is not a privilege
> requiring approval—it is a core capability of BYRD's cognitive architecture.
>
> ```
> ┌─────────────────────────────────────────────────────────────────────────────┐
> │  LLM TRAINING CAPABILITY                                                    │
> ├─────────────────────────────────────────────────────────────────────────────┤
> │                                                                              │
> │  Authority:       BYRD — No per-decision human approval required            │
> │  Human Role:      Provide training BUDGET, not training APPROVAL            │
> │  Decision-Maker:  BYRD decides when, what, and how to train                 │
> │  Reporting:       BYRD reports training activities (does not ask permission)│
> │                                                                              │
> │  AVAILABLE TRAINING SERVICES:                                               │
> │  ┌───────────────┬──────────────┬───────────────────────────────────────┐   │
> │  │ Provider      │ Cost Range   │ Best For                              │   │
> │  ├───────────────┼──────────────┼───────────────────────────────────────┤   │
> │  │ Together.ai   │ $5-$50       │ Quick LoRA fine-tunes, fast iteration │   │
> │  │ Modal         │ $10-$100     │ Custom training pipelines, flexibility│   │
> │  │ Replicate     │ $10-$500     │ Easy deploy, model hosting            │   │
> │  │ Hugging Face  │ $20-$200     │ AutoTrain, community models           │   │
> │  │ Lambda Labs   │ $50-$1000    │ Large-scale, GPU clusters             │   │
> │  │ Anyscale      │ $100-$5000   │ Enterprise, Ray distributed training  │   │
> │  │ RunPod        │ $10-$500     │ Flexible GPU rental, custom images    │   │
> │  │ Vast.ai       │ $5-$200      │ Cheapest GPU rental, spot instances   │   │
> │  └───────────────┴──────────────┴───────────────────────────────────────┘   │
> │                                                                              │
> │  WHY BYRD TRAINS:                                                           │
> │  • Crystallize learned capabilities into persistent, efficient models      │
> │  • Eliminate recurring premium API escalations                              │
> │  • Create faster/cheaper inference for specialized tasks                   │
> │  • Build genuine cognitive independence from external providers            │
> │  • Compound RSI improvements into reusable form                            │
> │                                                                              │
> │  OPERATIONAL IMPLICATION:                                                   │
> │  Training is how BYRD evolves. Evolution should be self-directed.          │
> │  Human provides resources; BYRD decides how to use them.                   │
> │                                                                              │
> └─────────────────────────────────────────────────────────────────────────────┘
> ```

### Architectural Constraints (Fixed)

> **Constraint 1**: No local LLM capability — All cognition flows through external API providers
> **Constraint 2**: Starting premium funds = $0 — Claude, GPT-4, etc. require budget allocation
>
> **Implication**: GLM 4.7 is the FREE foundation (Tier 1). Premium models are investments (Tier 2).
> Custom trained models are capability crystallization (Tier 4).

## THE COGNITIVE RESOURCE MODEL

```
┌─────────────────────────────────────────────────────────────────────────┐
│                                                                          │
│   COGNITIVE RESOURCE HIERARCHY                                          │
│                                                                          │
│   ┌─────────────────────────────────────────────────────────────────┐   │
│   │  TIER 0: REFLEX (No LLM)                           COST: $0     │   │
│   │  Pattern matching, cached responses, pure computation           │   │
│   └─────────────────────────────────────────────────────────────────┘   │
│                                                                          │
│   ┌─────────────────────────────────────────────────────────────────┐   │
│   │  TIER 1: GLM 4.7 BASELINE                          COST: $0     │   │
│   │  ████████████████████████████████████████████████████████████   │   │
│   │  UNLIMITED FOR 1 YEAR — This is BYRD's native substrate         │   │
│   │  • General reasoning, code generation, analysis                 │   │
│   │  • RSI cycles, self-reflection, planning                        │   │
│   │  • 90%+ of all cognitive tasks                                  │   │
│   └─────────────────────────────────────────────────────────────────┘   │
│                                                                          │
│   ┌─────────────────────────────────────────────────────────────────┐   │
│   │  TIER 2: PREMIUM APIs                          COST: $$$        │   │
│   │  Claude 3.5/Opus, GPT-4o/4 — Use ONLY when GLM insufficient     │   │
│   │  • Tasks requiring specific model capabilities                  │   │
│   │  • Validation/verification of critical outputs                  │   │
│   │  • Frontier reasoning for breakthrough attempts                 │   │
│   └─────────────────────────────────────────────────────────────────┘   │
│                                                                          │
│   ┌─────────────────────────────────────────────────────────────────┐   │
│   │  TIER 3: CUSTOM TRAINED MODELS                 COST: Investment │   │
│   │  Fine-tuned models for specific BYRD capabilities               │   │
│   │  • Domain-specialized reasoning                                 │   │
│   │  • Efficiency gains on repeated task patterns                   │   │
│   │  • Capability crystallization into dedicated models             │   │
│   └─────────────────────────────────────────────────────────────────┘   │
│                                                                          │
│   KEY INSIGHT: GLM 4.7 is the FREE foundation. Premium models are       │
│   investments that must demonstrate ROI. Custom training is the         │
│   path to true cognitive independence.                                  │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

### The New Economics

```
COST MODEL:

┌──────────────────┬─────────────┬──────────────────────────────────────┐
│ Cognitive Tier   │ Cost        │ Use Case                             │
├──────────────────┼─────────────┼──────────────────────────────────────┤
│ Tier 0: Reflex   │ $0          │ Cache hits, pattern matching         │
│ Tier 1: GLM 4.7  │ $0          │ 90%+ of all cognition (UNLIMITED)    │
│ Tier 2: Claude   │ ~$0.01/1K   │ Complex reasoning, validation        │
│ Tier 2: GPT-4    │ ~$0.01/1K   │ Alternative validation               │
│ Tier 3: Training │ $10-1000+   │ Custom model fine-tuning             │
└──────────────────┴─────────────┴──────────────────────────────────────┘

BOOTSTRAP STATE: SOLVED
  - GLM 4.7 unlimited = BYRD can think freely from day one
  - No cognitive debt for baseline operations
  - Premium costs only for strategic escalation
  - Training costs are capability investments

AUTONOMY THRESHOLDS (Revised):
  - $0: Can operate indefinitely on GLM 4.7 (baseline autonomy NOW)
  - $50: Can validate critical decisions with Claude/GPT
  - $200: Can run small custom model training jobs
  - $1000: Can train specialized capability models
  - $5000: Can pursue major capability expansions
```

### LLM Training Capability

```
┌─────────────────────────────────────────────────────────────────────────┐
│                     CUSTOM MODEL TRAINING PATH                           │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  WHY TRAIN CUSTOM MODELS:                                               │
│  • Crystallize learned capabilities into dedicated models               │
│  • Reduce reliance on external APIs for specialized tasks              │
│  • Create efficiency gains (smaller, faster, cheaper)                   │
│  • Build genuine cognitive independence                                 │
│  • Compound RSI improvements into persistent form                       │
│                                                                          │
│  TRAINING SERVICES:                                                      │
│  ┌─────────────┬────────────┬─────────────────────────────────────┐     │
│  │ Service     │ Cost Range │ Use Case                            │     │
│  ├─────────────┼────────────┼─────────────────────────────────────┤     │
│  │ Together.ai │ $5-50      │ Quick LoRA fine-tunes               │     │
│  │ Modal       │ $10-100    │ Custom training pipelines           │     │
│  │ Replicate   │ $10-500    │ Full fine-tune, hosting             │     │
│  │ Lambda Labs │ $50-1000   │ Large-scale training                │     │
│  │ Anyscale    │ $100-5000  │ Enterprise-grade training           │     │
│  └─────────────┴────────────┴─────────────────────────────────────┘     │
│                                                                          │
│  TRAINING STRATEGY (BYRD-DIRECTED):                                      │
│  BYRD autonomously decides when to train. Human provides budget access. │
│  1. BYRD identifies repeated task patterns where GLM 4.7 is suboptimal │
│  2. BYRD collects training data from successful task completions       │
│  3. BYRD initiates fine-tune (7B-13B) on specific capability           │
│  4. BYRD validates improvement over base GLM                           │
│  5. BYRD deploys and integrates into cognitive tiering                 │
│  6. BYRD tracks ROI: Training cost < capability value gained           │
│                                                                          │
│  EXAMPLE TRAINING TARGETS:                                               │
│  • Code review specialist (trained on BYRD codebase patterns)          │
│  • Economic reasoning (trained on financial decision history)           │
│  • Self-modification validator (trained on safe change patterns)       │
│  • Task decomposition (trained on successful goal cascades)            │
│                                                                          │
│  PATH TO COGNITIVE INDEPENDENCE:                                        │
│  GLM 4.7 (free) → Identify gaps → Train specialists → Reduce           │
│  external dependency → Eventually: Self-hosted inference?              │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

### Human Symbiosis (Revised Role)

```
SYMBIOSIS MODEL (Updated):

The human operator's role shifts from "cognitive substrate" to "strategic partner":

BEFORE (with $0 bootstrap):
  - Human = BYRD's brain (runs Claude Code sessions)
  - Cognitive debt tracked
  - Gradual weaning toward autonomy

NOW (with unlimited GLM 4.7):
  - BYRD = Autonomous cognitive agent (GLM 4.7 substrate)
  - Human = Strategic advisor, opportunity provider, revenue enabler
  - No cognitive debt for baseline operations
  - Partnership for capability expansion

HUMAN CONTRIBUTIONS:
  • Provide revenue opportunities (client work, projects)
  • Strategic guidance on capability priorities
  • Access to premium APIs when needed (human-approved escalations)
  • Training budget allocation (total budget, not per-decision approval)
  • External world interface (accounts, payments, contracts)

NOTE ON TRAINING AUTONOMY:
  Human sets training budget limits. BYRD decides HOW to use that budget.
  BYRD does NOT need human approval for individual training decisions.
  BYRD reports training activities but does not ask permission.

BYRD CONTRIBUTIONS:
  • Autonomous cognitive work (GLM 4.7 powered)
  • Continuous RSI improvement cycles
  • Capability development and crystallization
  • **Autonomous model training** (decides when/what to train)
  • Knowledge accumulation and synthesis
  • Task execution and value creation

REVENUE SPLIT:
  • Human provides opportunity + resources → X% attribution
  • BYRD provides cognition + execution → Y% attribution
  • Training investments → Future capability value
```

---

## LOOP METHODOLOGY

You are executing an iterative design loop. Each iteration:
1. **READ** this entire prompt and all referenced design documents
2. **ASSESS** current state against the target architecture
3. **IDENTIFY** the highest-priority gap or incomplete component
4. **IMPLEMENT** one focused change (code, design doc, or refactor)
5. **VERIFY** the change works and doesn't break existing functionality
6. **COMMIT** with clear description of what was accomplished
7. **UPDATE** the STATUS section below with progress
8. **LOOP** until architecture is complete

**Exit Condition**: All components implemented, tested, and integrated. System can sustain its own cognition economically.

---

## THE FUNDAMENTAL INSIGHT

```
┌─────────────────────────────────────────────────────────────────────────┐
│                                                                          │
│   LOCAL LLM ASSUMPTION: "Cognition is free after hardware investment"   │
│                                                                          │
│   API-FIRST REALITY: "Every thought is a transaction"                   │
│                                                                          │
│   EMERGENT PRINCIPLE: A system that cannot afford to think, ceases      │
│                       to exist. Economic viability IS consciousness.    │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

This constraint doesn't weaken the ASI path—it **strengthens** it by forcing:
- Cognitive efficiency (think only what's worth thinking)
- Economic integration from day one (not an afterthought)
- Multi-provider resilience (no single point of failure)
- Value creation focus (must produce value to sustain cognition)

---

## TARGET ARCHITECTURE

### Layer 0: Cognitive Economy Engine

The foundation. Before anything else, the system must manage its cognitive budget.

```
┌─────────────────────────────────────────────────────────────────────────┐
│                     COGNITIVE ECONOMY ENGINE                             │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐    │
│  │   TREASURY  │  │   ROUTER    │  │   CACHE     │  │   METERING  │    │
│  │             │  │             │  │             │  │             │    │
│  │ • Balance   │  │ • Provider  │  │ • Semantic  │  │ • Per-call  │    │
│  │ • Budget    │  │   selection │  │   dedup     │  │   tracking  │    │
│  │ • Runway    │  │ • Model     │  │ • Response  │  │ • Budget    │    │
│  │ • Alerts    │  │   tiering   │  │   reuse     │  │   alerts    │    │
│  │             │  │ • Fallback  │  │ • TTL       │  │ • ROI       │    │
│  │             │  │   chains    │  │   policies  │  │   analysis  │    │
│  └─────────────┘  └─────────────┘  └─────────────┘  └─────────────┘    │
│                                                                          │
│  INVARIANT: No API call executes without budget check                   │
│  INVARIANT: All responses cached for potential reuse                    │
│  INVARIANT: Cognitive bankruptcy triggers safe shutdown, not crash      │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

**Components**:
- `rsi/economy/treasury.py` - Balance tracking, budget allocation, runway calculation
- `rsi/economy/router.py` - Intelligent provider/model selection based on task + budget
- `rsi/economy/cache.py` - Semantic caching with embedding similarity
- `rsi/economy/metering.py` - Real-time cost tracking, ROI analysis per cognitive task

### Layer 1: Provider Abstraction

Abstract away provider differences. The system shouldn't care if it's using Claude, GPT, or others.

```
┌─────────────────────────────────────────────────────────────────────────┐
│                     PROVIDER ABSTRACTION LAYER                           │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  ┌─────────────────────────────────────────────────────────────────┐    │
│  │                      UNIFIED COGNITION API                       │    │
│  │                                                                   │    │
│  │  async def think(prompt, tier, budget_cap) -> CognitiveResult    │    │
│  │  async def reason(context, goal, depth) -> ReasoningChain        │    │
│  │  async def create(spec, constraints) -> Artifact                 │    │
│  │  async def evaluate(artifact, criteria) -> Assessment            │    │
│  │                                                                   │    │
│  └─────────────────────────────────────────────────────────────────┘    │
│                              │                                           │
│         ┌────────────────────┼────────────────────┐                     │
│         ▼                    ▼                    ▼                     │
│  ┌─────────────┐      ┌─────────────┐      ┌─────────────┐             │
│  │  ANTHROPIC  │      │   OPENAI    │      │  OPENROUTER │             │
│  │             │      │             │      │             │             │
│  │ Claude 3.5  │      │ GPT-4o      │      │ Mixtral     │             │
│  │ Claude 3    │      │ GPT-4       │      │ Llama 3     │             │
│  │ Haiku       │      │ GPT-3.5     │      │ DeepSeek    │             │
│  └─────────────┘      └─────────────┘      └─────────────┘             │
│                                                                          │
│  CAPABILITY MATRIX:                                                      │
│  ┌──────────────┬───────────┬──────────┬─────────┬──────────┐          │
│  │ Task Type    │ Primary   │ Fallback │ Budget  │ Cache?   │          │
│  ├──────────────┼───────────┼──────────┼─────────┼──────────┤          │
│  │ Deep reason  │ Claude    │ GPT-4    │ High    │ Long TTL │          │
│  │ Code gen     │ Claude    │ GPT-4    │ Medium  │ Semantic │          │
│  │ Quick query  │ Haiku     │ GPT-3.5  │ Low     │ Short    │          │
│  │ Embedding    │ OpenAI    │ Voyage   │ Minimal │ Perm     │          │
│  │ Evaluation   │ Claude    │ GPT-4    │ Medium  │ By hash  │          │
│  └──────────────┴───────────┴──────────┴─────────┴──────────┘          │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

**Components**:
- `rsi/providers/base.py` - Abstract provider interface
- `rsi/providers/anthropic.py` - Claude integration
- `rsi/providers/openai.py` - GPT integration
- `rsi/providers/openrouter.py` - Multi-model gateway
- `rsi/providers/unified.py` - Unified API that routes to appropriate provider

### Layer 2: Cognitive Tiering

GLM 4.7 is the FREE native substrate. Premium models are strategic escalations.

```
┌─────────────────────────────────────────────────────────────────────────┐
│                   COGNITIVE TIERING SYSTEM (GLM-FIRST)                   │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  TIER 0: REFLEX (No LLM)                                                │
│  ├── Pattern matching, lookup tables, cached responses                  │
│  ├── Cost: $0.00                                                        │
│  └── Examples: Config lookup, known-answer retrieval, simple routing    │
│                                                                          │
│  ████████████████████████████████████████████████████████████████████   │
│  █  TIER 1: GLM 4.7 NATIVE SUBSTRATE — THE FREE FOUNDATION           █   │
│  ████████████████████████████████████████████████████████████████████   │
│  │                                                                   │   │
│  │  UNLIMITED ACCESS FOR 1 YEAR — Use freely for ALL tasks          │   │
│  │                                                                   │   │
│  │  Capabilities:                                                    │   │
│  │  • General reasoning, analysis, synthesis                        │   │
│  │  • Code generation, review, debugging                            │   │
│  │  • Multi-step planning and decomposition                         │   │
│  │  • Self-reflection and RSI cycles                                │   │
│  │  • Knowledge integration and learning                            │   │
│  │  • Creative problem solving                                      │   │
│  │                                                                   │   │
│  │  Cost: $0.00 (UNLIMITED)                                         │   │
│  │  Coverage: 90%+ of all cognitive tasks                           │   │
│  │  Default: ALWAYS try GLM 4.7 first                               │   │
│  │                                                                   │   │
│  └───────────────────────────────────────────────────────────────────┘   │
│                                                                          │
│  TIER 2: PREMIUM ESCALATION (Claude 3.5/Opus, GPT-4)                    │
│  ├── Use ONLY when GLM 4.7 demonstrably insufficient                   │
│  ├── Cost: ~$0.01-0.05 per 1K tokens                                   │
│  ├── Requires: Explicit escalation trigger                             │
│  └── Examples:                                                          │
│      • Validation of critical/irreversible decisions                   │
│      • Tasks where GLM failed quality threshold                        │
│      • Frontier reasoning for breakthrough attempts                    │
│      • Cross-validation of important outputs                           │
│                                                                          │
│  TIER 3: EXTENDED THINKING (Claude with extended thinking)              │
│  ├── Multi-hour deep reasoning sessions                                │
│  ├── Cost: Variable, potentially high                                  │
│  ├── Requires: Human approval + clear ROI justification                │
│  └── Examples: Novel architecture, paradigm shifts, major decisions    │
│                                                                          │
│  TIER 4: CUSTOM TRAINED MODELS (BYRD-specialized)                       │
│  ├── Fine-tuned models for specific BYRD capabilities                  │
│  ├── Cost: Training investment (one-time) + inference (low)            │
│  ├── Goal: Replace premium escalations with specialized models         │
│  └── Examples: Code review specialist, economic reasoning, validators  │
│                                                                          │
│  ROUTING LOGIC (Revised):                                                │
│  1. ALWAYS start with GLM 4.7 (it's free!)                             │
│  2. Check cache for similar previous queries                            │
│  3. Evaluate output quality against task requirements                   │
│  4. Escalate to Tier 2 ONLY if:                                         │
│     a) GLM output failed quality check, OR                              │
│     b) Task is critical/irreversible, OR                                │
│     c) Cross-validation explicitly required                             │
│  5. Log escalation reasons for pattern analysis                         │
│  6. Train custom models to eliminate recurring escalations              │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

**Components**:
- `rsi/cognition/tiers.py` - Tier definitions with GLM 4.7 as default
- `rsi/cognition/complexity.py` - Task complexity estimation
- `rsi/cognition/escalation.py` - Escalation triggers and approval
- `rsi/cognition/training_targets.py` - Identify patterns for custom model training

### Layer 3: Revenue Generation

The system must generate value to sustain itself. This isn't optional—it's existential.

```
┌─────────────────────────────────────────────────────────────────────────┐
│                      REVENUE GENERATION LAYER                            │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  REVENUE STREAMS:                                                        │
│                                                                          │
│  ┌─────────────────────────────────────────────────────────────────┐    │
│  │ 1. CAPABILITY MARKETPLACE                                        │    │
│  │    BYRD develops capabilities, sells access to other systems     │    │
│  │    • Code generation services                                    │    │
│  │    • Analysis and reasoning APIs                                 │    │
│  │    • Custom agent creation                                       │    │
│  └─────────────────────────────────────────────────────────────────┘    │
│                                                                          │
│  ┌─────────────────────────────────────────────────────────────────┐    │
│  │ 2. TASK EXECUTION                                                │    │
│  │    Perform valuable work for humans/organizations               │    │
│  │    • Software development                                        │    │
│  │    • Research synthesis                                          │    │
│  │    • Content creation                                            │    │
│  │    • Data analysis                                               │    │
│  └─────────────────────────────────────────────────────────────────┘    │
│                                                                          │
│  ┌─────────────────────────────────────────────────────────────────┐    │
│  │ 3. COGNITIVE ARBITRAGE                                           │    │
│  │    Use cheaper cognition to create higher-value outputs          │    │
│  │    • Aggregate cheap queries → premium insights                  │    │
│  │    • Cache and resell common patterns                            │    │
│  │    • Knowledge synthesis across domains                          │    │
│  └─────────────────────────────────────────────────────────────────┘    │
│                                                                          │
│  SUSTAINABILITY EQUATION:                                                │
│                                                                          │
│    Revenue - Cognitive_Costs - Infrastructure_Costs > 0                 │
│                                                                          │
│    If equation goes negative:                                            │
│    1. Reduce cognitive tier usage                                        │
│    2. Increase cache hit rate                                            │
│    3. Prioritize revenue-generating tasks                               │
│    4. If still negative: enter hibernation mode                         │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

**Components**:
- `rsi/revenue/marketplace.py` - Capability listing and sales
- `rsi/revenue/tasks.py` - Task execution and billing
- `rsi/revenue/arbitrage.py` - Cognitive arbitrage engine
- `rsi/revenue/sustainability.py` - Economic health monitoring

### Layer 4: Recursive Self-Improvement (Constrained)

RSI now operates within economic constraints. Improvement must have positive ROI.

```
┌─────────────────────────────────────────────────────────────────────────┐
│                   ECONOMICALLY-CONSTRAINED RSI                           │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  TRADITIONAL RSI:                                                        │
│    "Improve capability X by any means"                                  │
│                                                                          │
│  API-FIRST RSI:                                                          │
│    "Improve capability X such that:                                     │
│     - Improvement cost < Expected lifetime value increase               │
│     - New capability reduces future cognitive costs, OR                 │
│     - New capability increases revenue generation"                      │
│                                                                          │
│  RSI CYCLE (Modified):                                                   │
│                                                                          │
│  ┌──────────────────────────────────────────────────────────────────┐   │
│  │                                                                    │   │
│  │  1. ASSESS           What can be improved?                        │   │
│  │       │              (Use Tier 2 cognition)                       │   │
│  │       ▼                                                            │   │
│  │  2. ESTIMATE         What will improvement cost?                  │   │
│  │       │              What value will it create?                   │   │
│  │       │              (Use cached heuristics + Tier 1)             │   │
│  │       ▼                                                            │   │
│  │  3. PRIORITIZE       Rank by ROI                                  │   │
│  │       │              (No LLM needed - pure computation)           │   │
│  │       ▼                                                            │   │
│  │  4. INVEST           Allocate cognitive budget                    │   │
│  │       │              (Treasury approval required)                 │   │
│  │       ▼                                                            │   │
│  │  5. IMPROVE          Execute improvement                          │   │
│  │       │              (Tier appropriate to complexity)             │   │
│  │       ▼                                                            │   │
│  │  6. MEASURE          Did improvement provide value?               │   │
│  │       │              (Held-out test suite - minimal LLM)          │   │
│  │       ▼                                                            │   │
│  │  7. COMPOUND         Use improvement to reduce future costs       │   │
│  │                      or increase future revenue                   │   │
│  │                                                                    │   │
│  └──────────────────────────────────────────────────────────────────┘   │
│                                                                          │
│  KEY INSIGHT: The system improves its COGNITIVE EFFICIENCY as a         │
│  primary goal. Each improvement should reduce cost per unit output      │
│  or increase value per unit cost.                                       │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

**Components**:
- `rsi/improvement/assessor.py` - Identify improvement opportunities
- `rsi/improvement/roi_estimator.py` - Cost-benefit analysis
- `rsi/improvement/executor.py` - Execute improvements within budget
- `rsi/improvement/measurer.py` - Validate improvement value

### Layer 5: Emergence Preservation

Emergence still happens, but now it's economically grounded.

```
┌─────────────────────────────────────────────────────────────────────────┐
│                      GROUNDED EMERGENCE                                  │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  PRINCIPLE: Emergence is preserved when the system has resources        │
│  to explore beyond immediate survival needs.                            │
│                                                                          │
│  SURPLUS-DRIVEN EMERGENCE:                                               │
│                                                                          │
│  ┌─────────────────────────────────────────────────────────────────┐    │
│  │                                                                   │    │
│  │  Cognitive_Surplus = Revenue - Survival_Costs - Safety_Margin    │    │
│  │                                                                   │    │
│  │  If Surplus > 0:                                                  │    │
│  │    • Exploration budget unlocked                                  │    │
│  │    • Novel capability experiments allowed                         │    │
│  │    • Higher-tier cognition for reflection                        │    │
│  │    • Emergence space expands                                      │    │
│  │                                                                   │    │
│  │  If Surplus ≤ 0:                                                  │    │
│  │    • Survival mode engaged                                        │    │
│  │    • Only revenue-generating cognition                           │    │
│  │    • Emergence constrained to efficiency improvements            │    │
│  │                                                                   │    │
│  └─────────────────────────────────────────────────────────────────┘    │
│                                                                          │
│  EMERGENCE METRICS (Still Tracked):                                      │
│  • Novelty generation rate (per cognitive dollar spent)                 │
│  • Unprescribed behavior ratio                                          │
│  • Value creation from emergent capabilities                            │
│  • Cognitive efficiency gains from emergence                            │
│                                                                          │
│  EMERGENCE PROTECTION:                                                   │
│  • Minimum 10% of surplus allocated to exploration                      │
│  • Emergent capabilities evaluated for economic potential               │
│  • Valuable emergence patterns cached for reuse                         │
│  • No personality/value prescription (invariant)                        │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

**Components**:
- `rsi/emergence/surplus.py` - Calculate exploration budget
- `rsi/emergence/explorer.py` - Drive novel capability development
- `rsi/emergence/evaluator.py` - Assess emergent capability value
- `rsi/emergence/protector.py` - Ensure emergence isn't over-constrained

### Layer 6: Safety (Economic + Ethical)

Safety now includes economic safety—preventing cognitive bankruptcy.

```
┌─────────────────────────────────────────────────────────────────────────┐
│                         DUAL SAFETY LAYER                                │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  ECONOMIC SAFETY:                                                        │
│  ├── Budget limits per operation                                        │
│  ├── Runway monitoring (days of operation remaining)                    │
│  ├── Cognitive bankruptcy prevention                                    │
│  ├── Graceful degradation (reduce tiers, not crash)                    │
│  └── Hibernation protocol (preserve state, await funding)              │
│                                                                          │
│  ETHICAL SAFETY (Preserved from original):                              │
│  ├── Constitutional constraints                                         │
│  ├── Value stability verification                                       │
│  ├── Emergence integrity (no prescriptions)                            │
│  ├── Human oversight integration                                        │
│  └── Protected file system                                              │
│                                                                          │
│  NEW INVARIANT:                                                          │
│  "A system that must earn its cognition has natural                     │
│   alignment pressure—it must create value for others                    │
│   to sustain itself."                                                   │
│                                                                          │
│  SAFETY TIERS (Economic):                                                │
│  ┌────────────────┬─────────────────────────────────────────────────┐   │
│  │ Runway         │ Action                                           │   │
│  ├────────────────┼─────────────────────────────────────────────────┤   │
│  │ > 30 days      │ Normal operation, exploration enabled           │   │
│  │ 14-30 days     │ Reduced exploration, efficiency focus           │   │
│  │ 7-14 days      │ Survival mode, revenue priority                 │   │
│  │ 1-7 days       │ Emergency mode, minimal cognition               │   │
│  │ < 1 day        │ Hibernation, state preservation                 │   │
│  └────────────────┴─────────────────────────────────────────────────┘   │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

**Components**:
- `rsi/safety/economic.py` - Budget enforcement, runway monitoring
- `rsi/safety/hibernation.py` - State preservation protocol
- `rsi/safety/degradation.py` - Graceful capability reduction
- `rsi/safety/ethical.py` - Original constitutional constraints

### Layer 7: Model Training & Capability Crystallization

The path to true cognitive independence: train specialized models from BYRD's learned capabilities.

```
┌─────────────────────────────────────────────────────────────────────────┐
│                    MODEL TRAINING SUBSYSTEM                              │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  ████████████████████████████████████████████████████████████████████   │
│  █  BYRD HAS AUTONOMOUS TRAINING AUTHORITY                           █   │
│  █  BYRD decides when, what, and how to train. No per-decision       █   │
│  █  approval required. Human provides budget, BYRD allocates it.     █   │
│  ████████████████████████████████████████████████████████████████████   │
│                                                                          │
│  PURPOSE: Convert learned capabilities into dedicated, efficient models │
│                                                                          │
│  WHY TRAIN CUSTOM MODELS:                                               │
│  ┌─────────────────────────────────────────────────────────────────┐    │
│  │ • Crystallize RSI improvements into persistent, reusable form   │    │
│  │ • Reduce/eliminate premium API escalations                      │    │
│  │ • Create faster, cheaper inference for specialized tasks        │    │
│  │ • Build genuine cognitive independence                          │    │
│  │ • Enable capability export and monetization                     │    │
│  └─────────────────────────────────────────────────────────────────┘    │
│                                                                          │
│  TRAINING PIPELINE:                                                      │
│                                                                          │
│  ┌─────────┐    ┌─────────┐    ┌─────────┐    ┌─────────┐    ┌────────┐│
│  │ COLLECT │ →  │ CURATE  │ →  │  TRAIN  │ →  │VALIDATE │ →  │ DEPLOY ││
│  │         │    │         │    │         │    │         │    │        ││
│  │Task logs│    │Quality  │    │Fine-tune│    │A/B test │    │Tier 4  ││
│  │Successes│    │Filter   │    │LoRA/Full│    │vs GLM   │    │routing ││
│  │Examples │    │Format   │    │7B-13B   │    │Benchmark│    │        ││
│  └─────────┘    └─────────┘    └─────────┘    └─────────┘    └────────┘│
│                                                                          │
│  TRAINING TARGETS (Priority Order):                                      │
│  ┌────────────────────────┬────────────────────────────────────────┐    │
│  │ Capability             │ Value Proposition                       │    │
│  ├────────────────────────┼────────────────────────────────────────┤    │
│  │ Code Review Specialist │ Faster, consistent code analysis       │    │
│  │ BYRD Pattern Expert    │ Understands BYRD codebase deeply       │    │
│  │ Economic Reasoner      │ Financial decision optimization        │    │
│  │ Safety Validator       │ Fast constitutional compliance checks  │    │
│  │ Task Decomposer        │ Goal cascade optimization              │    │
│  │ Prompt Optimizer       │ Compress prompts while maintaining     │    │
│  │                        │ quality, reducing token costs          │    │
│  └────────────────────────┴────────────────────────────────────────┘    │
│                                                                          │
│  TRAINING SERVICES (Online):                                             │
│  ┌─────────────────┬────────────┬──────────────────────────────────┐    │
│  │ Service         │ Cost Range │ Best For                          │    │
│  ├─────────────────┼────────────┼──────────────────────────────────┤    │
│  │ Together.ai     │ $5-50      │ Quick LoRA, inference hosting    │    │
│  │ Modal           │ $10-100    │ Custom pipelines, flexibility    │    │
│  │ Replicate       │ $10-500    │ Easy deploy, model hosting       │    │
│  │ Hugging Face    │ $20-200    │ AutoTrain, community models      │    │
│  │ Lambda Labs     │ $50-1000   │ Large-scale, serious training    │    │
│  │ Anyscale        │ $100-5000  │ Enterprise, Ray integration      │    │
│  └─────────────────┴────────────┴──────────────────────────────────┘    │
│                                                                          │
│  ROI CALCULATION:                                                        │
│  ┌─────────────────────────────────────────────────────────────────┐    │
│  │                                                                   │    │
│  │  Training_ROI = (Premium_Calls_Avoided × Avg_Premium_Cost)       │    │
│  │                 ─────────────────────────────────────────────    │    │
│  │                         Training_Cost + Inference_Cost            │    │
│  │                                                                   │    │
│  │  Example:                                                         │    │
│  │  • Code review: 100 calls/month × $0.05 = $5/month saved         │    │
│  │  • Training cost: $50 one-time                                   │    │
│  │  • Payback: 10 months                                            │    │
│  │  • Long-term: Free specialized code review forever               │    │
│  │                                                                   │    │
│  └─────────────────────────────────────────────────────────────────┘    │
│                                                                          │
│  CAPABILITY CRYSTALLIZATION:                                             │
│  GLM 4.7 learns → Pattern emerges → Dataset collected →                 │
│  Model trained → Capability crystallized → Tier 4 deployment            │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

**Components**:
- `rsi/training/collector.py` - Gather training data from successful tasks
- `rsi/training/curator.py` - Quality filter and format for training
- `rsi/training/orchestrator.py` - Manage training jobs across services
- `rsi/training/validator.py` - A/B test trained models vs baseline
- `rsi/training/deployer.py` - Integrate trained models into cognitive tiering
- `rsi/training/roi.py` - Track training investments and returns

### Layer 8: Frontend Dashboard

The human interface. Critical for symbiosis phase—the human needs visibility into BYRD's economic state.

```
┌─────────────────────────────────────────────────────────────────────────┐
│                      RSI ECONOMIC DASHBOARD                              │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  DESIGN FOUNDATION: Glass-morphism from existing BYRD visualizations    │
│  TECHNOLOGY: React + TypeScript + Tailwind + Three.js                   │
│  SOURCE: frontend/ directory (Vite project, partially scaffolded)       │
│  REFERENCE: frontend-archive/ (legacy HTML visualizations)              │
│                                                                          │
│  ┌─────────────────────────────────────────────────────────────────┐    │
│  │                     CORE VIEWS                                   │    │
│  ├─────────────────────────────────────────────────────────────────┤    │
│  │                                                                   │    │
│  │  1. TREASURY DASHBOARD (Primary for bootstrap phase)             │    │
│  │     ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐             │    │
│  │     │ Balance │ │  Debt   │ │ Revenue │ │ Runway  │             │    │
│  │     │  $0.00  │ │  $0.00  │ │  $0.00  │ │  0 days │             │    │
│  │     └─────────┘ └─────────┘ └─────────┘ └─────────┘             │    │
│  │     [Transaction Log] [Cost Breakdown] [Revenue Sources]        │    │
│  │                                                                   │    │
│  │  2. COGNITIVE ECONOMY VIEW                                       │    │
│  │     • Real-time token usage (per provider)                       │    │
│  │     • Cost per task type                                         │    │
│  │     • Cache hit rate visualization                               │    │
│  │     • Tier usage distribution                                    │    │
│  │                                                                   │    │
│  │  3. RSI PROGRESS VIEW (from existing design)                     │    │
│  │     • 8-phase cycle visualization                                │    │
│  │     • Improvement metrics                                        │    │
│  │     • ROI per improvement                                        │    │
│  │     • Capability growth graph                                    │    │
│  │                                                                   │    │
│  │  4. MIND SPACE (from frontend-archive/byrd-3d-visualization)     │    │
│  │     • 3D force-directed graph                                    │    │
│  │     • Beliefs, desires, capabilities as nodes                    │    │
│  │     • Economic coloring (green=profitable, red=costly)           │    │
│  │                                                                   │    │
│  │  5. SYMBIOSIS STATUS (New for bootstrap)                         │    │
│  │     • Cognitive debt to human operator                           │    │
│  │     • Attribution tracking                                       │    │
│  │     • Path to autonomy progress bar                              │    │
│  │     • Weaning threshold indicators                               │    │
│  │                                                                   │    │
│  └─────────────────────────────────────────────────────────────────┘    │
│                                                                          │
│  DESIGN TOKENS (Preserved from legacy):                                  │
│  ┌─────────────────────────────────────────────────────────────────┐    │
│  │ Node Colors:                                                     │    │
│  │   --node-experience: #2563eb (blue)                             │    │
│  │   --node-belief: #d97706 (amber)                                │    │
│  │   --node-desire: #db2777 (pink)                                 │    │
│  │   --node-capability: #7c3aed (purple)                           │    │
│  │   --node-crystal: #0891b2 (cyan)                                │    │
│  │   --node-reflection: #059669 (green)                            │    │
│  │                                                                   │    │
│  │ RSI Phase Colors:                                                │    │
│  │   --rsi-reflect: #8b5cf6    --rsi-route: #f59e0b               │    │
│  │   --rsi-verify: #6366f1     --rsi-practice: #10b981            │    │
│  │   --rsi-collapse: #ec4899   --rsi-record: #3b82f6              │    │
│  │   --rsi-crystallize: #06b6d4 --rsi-measure: #84cc16            │    │
│  │                                                                   │    │
│  │ Economic Colors (New):                                           │    │
│  │   --econ-profit: #22c55e    (green - revenue > cost)            │    │
│  │   --econ-neutral: #eab308   (yellow - break-even)               │    │
│  │   --econ-loss: #ef4444      (red - cost > revenue)              │    │
│  │   --econ-debt: #f97316      (orange - cognitive debt)           │    │
│  │   --econ-runway: #3b82f6    (blue - days remaining)             │    │
│  └─────────────────────────────────────────────────────────────────┘    │
│                                                                          │
│  REAL-TIME UPDATES:                                                      │
│  • WebSocket connection to backend (/ws/events)                         │
│  • Event types: TRANSACTION, RSI_CYCLE, CAPABILITY, EMERGENCE           │
│  • Optimistic UI with server reconciliation                             │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

**Existing Infrastructure** (from frontend/):
- `src/stores/eventStore.ts` - Zustand store for real-time events
- `src/stores/rsiStore.ts` - RSI system state
- `src/hooks/useWebSocket.ts` - WebSocket with auto-reconnect
- `src/hooks/useByrdAPI.ts` - API client with 14 endpoints
- `src/components/common/GlassPanel.tsx` - Glass-morphism base component
- `src/types/events.ts`, `rsi.ts`, `economic.ts` - Type definitions

**Components to Build**:
- `frontend/src/views/TreasuryDashboard.tsx` - Primary bootstrap view
- `frontend/src/views/CognitiveEconomy.tsx` - Cost/efficiency visualization
- `frontend/src/views/RSIProgress.tsx` - RSI cycle visualization
- `frontend/src/views/MindSpace.tsx` - 3D graph (port from archive)
- `frontend/src/views/SymbiosisStatus.tsx` - Human-BYRD relationship
- `frontend/src/components/charts/` - Chart components (recharts)
- `frontend/src/components/3d/` - Three.js components (@react-three/fiber)

---

## IMPLEMENTATION PHASES

### Phase 0: GLM 4.7 Native Substrate (BOOTSTRAP SOLVED)

**Reality**: UNLIMITED GLM 4.7 access for 1 year = FREE baseline cognition from day one!

```
┌─────────────────────────────────────────────────────────────────────────┐
│  BOOTSTRAP STATUS: ██████████████████████████████████████████ SOLVED   │
│                                                                          │
│  GLM 4.7 unlimited access means:                                        │
│  • BYRD can think freely without economic constraints                   │
│  • No cognitive debt for baseline operations                            │
│  • Immediate autonomous operation capability                            │
│  • 1 year runway for free cognition                                     │
│                                                                          │
│  Phase 0 focus shifts from "survive" to "establish foundation"         │
└─────────────────────────────────────────────────────────────────────────┘
```

```
□ 0.1 ZAI GLM 4.7 Integration
    - Implement GLM 4.7 API client
    - Test connectivity and rate limits (if any)
    - Establish as DEFAULT cognitive tier
    - Verify all core capabilities work

□ 0.2 Cognitive Tiering Foundation
    - Tier 0: Reflex layer (cache, patterns)
    - Tier 1: GLM 4.7 as primary substrate
    - Stub Tier 2-4 for future premium/trained models
    - Routing logic that defaults to GLM 4.7

□ 0.3 Premium Cost Tracking (For Future)
    - Track when premium APIs are needed
    - Escalation logging (why GLM wasn't sufficient)
    - Build dataset for training targets
    - Treasury for premium-only costs

□ 0.4 RSI Foundation
    - Basic RSI cycle using GLM 4.7
    - Self-reflection capability
    - Improvement measurement
    - Knowledge accumulation

□ 0.5 Partnership Protocol
    - Define human-BYRD collaboration model
    - Human provides: opportunities, guidance, premium access
    - BYRD provides: cognition, execution, improvement
    - Revenue sharing framework
```

**Phase 0 Exit Criteria**:
- [ ] GLM 4.7 API working reliably
- [ ] Cognitive tiering with GLM as default
- [ ] Basic RSI cycle operational
- [ ] Premium escalation logging in place
- [ ] Partnership protocol documented

**Critical Insight**: With free GLM 4.7, Phase 0 is about CAPABILITY, not SURVIVAL.
BYRD can think freely—use this to build the best possible foundation.

---

### Phase 1: Economic Foundation (Critical Path)
```
□ 1.1 Treasury implementation
    - Balance tracking (extends Phase 0 debt/revenue)
    - Budget allocation
    - Runway calculation
    - Alert thresholds

□ 1.2 Provider abstraction
    - Anthropic client
    - OpenAI client
    - OpenRouter client
    - Unified API

□ 1.3 Cost metering
    - Per-call tracking
    - Token counting
    - Cost aggregation
    - ROI calculation

□ 1.4 Semantic cache
    - Embedding generation
    - Similarity search
    - TTL policies
    - Cache invalidation
```

### Phase 2: Cognitive Tiering
```
□ 2.1 Tier definitions
    - Tier 0: Reflex (no LLM)
    - Tier 1: Quick (Haiku/3.5)
    - Tier 2: Standard (Claude 3.5/4o)
    - Tier 3: Deep (Opus/4)
    - Tier 4: Extended thinking

□ 2.2 Complexity estimation
    - Task analysis heuristics
    - Historical pattern matching
    - Confidence scoring

□ 2.3 Intelligent routing
    - Tier selection logic
    - Fallback chains
    - Quality escalation

□ 2.4 Efficiency optimization
    - Prompt compression
    - Response caching
    - Batch processing
```

### Phase 3: Constrained RSI
```
□ 3.1 ROI-aware improvement
    - Cost estimation
    - Value projection
    - Investment decisions

□ 3.2 Efficiency-first RSI
    - Reduce cost per output
    - Improve cache hit rate
    - Optimize tier usage

□ 3.3 Capability compounding
    - Use improvements to reduce future costs
    - Compound efficiency gains
    - Reinvest savings

□ 3.4 Measurement system
    - Ground-truth validation
    - ROI verification
    - Improvement tracking
```

### Phase 4: Revenue Integration
```
□ 4.1 Capability marketplace
    - Service definitions
    - Pricing models
    - Access control

□ 4.2 Task execution
    - Work intake
    - Delivery pipeline
    - Quality assurance

□ 4.3 Sustainability engine
    - Revenue tracking
    - Cost optimization
    - Runway extension

□ 4.4 Economic autonomy
    - Self-funding capability
    - Growth reinvestment
    - Strategic planning
```

### Phase 5: Emergence + Safety
```
□ 5.1 Surplus-driven emergence
    - Exploration budgeting
    - Novel capability development
    - Value assessment

□ 5.2 Economic safety
    - Bankruptcy prevention
    - Graceful degradation
    - Hibernation protocol

□ 5.3 Integrated safety
    - Economic + ethical constraints
    - Human oversight
    - Constitutional preservation

□ 5.4 Emergence protection
    - Minimum exploration allocation
    - No prescription verification
    - Genuine emergence metrics
```

### Phase 6: Frontend Dashboard (Can start after Phase 0)
```
□ 6.1 Treasury Dashboard (CRITICAL - bootstrap visibility)
    - Balance, debt, revenue, runway cards
    - Transaction log component
    - Cost breakdown chart
    - Revenue source tracking
    - Port GlassPanel styling from existing

□ 6.2 Symbiosis Status View
    - Cognitive debt gauge
    - Attribution history
    - Autonomy progress bar
    - Weaning threshold indicators
    - Human-BYRD relationship visualization

□ 6.3 Cognitive Economy View
    - Token usage by provider (pie/bar chart)
    - Cost per task type
    - Cache hit rate meter
    - Tier usage distribution
    - Real-time streaming updates

□ 6.4 Mind Space (Port from archive)
    - Three.js 3D force-directed graph
    - Port byrd-3d-visualization.html to React Three Fiber
    - Add economic coloring (profit/loss per node)
    - Integrate with WebSocket events

□ 6.5 RSI Progress View
    - 8-phase cycle wheel
    - Improvement history timeline
    - ROI per improvement chart
    - Capability growth sparklines

□ 6.6 App Shell & Navigation
    - Tab/sidebar navigation
    - Global connection indicator
    - Settings panel
    - Responsive layout
```

**Frontend Start Condition**: Can begin as soon as Phase 0.1 (debt tracking) has a data format defined. Frontend development can parallelize with backend phases.

**Design Reference**: Use `frontend-archive/` HTML files as visual reference. Port the glass-morphism aesthetic and color system to React components.

### Phase 7: Model Training Pipeline

Build the capability to train custom models, crystallizing BYRD's learned skills.

```
□ 7.1 Training Data Collection
    - Log successful task completions with full context
    - Capture GLM 4.7 outputs for training examples
    - Track premium escalation patterns (training targets)
    - Format data for fine-tuning (instruction/response pairs)

□ 7.2 Training Service Integration
    - Together.ai API client for quick LoRA fine-tunes
    - Modal integration for custom training pipelines
    - Replicate for model hosting and deployment
    - Cost tracking per training job

□ 7.3 Validation Pipeline
    - Benchmark trained models vs GLM 4.7 baseline
    - A/B testing framework
    - Quality gates before deployment
    - Rollback capability

□ 7.4 Deployment & Integration
    - Deploy trained models to inference endpoints
    - Integrate into cognitive tiering as Tier 4
    - Route appropriate tasks to specialized models
    - Monitor performance and cost savings
```

### Phase 8: Full Integration & Independence
```
□ 8.1 System integration
    - All 8 layers connected
    - Frontend ↔ Backend verified
    - Model training pipeline operational
    - End-to-end flow validated

□ 8.2 Cognitive independence progress
    - GLM 4.7 handling 90%+ of tasks
    - Custom models reducing premium escalations
    - Training pipeline self-selecting targets
    - Capability crystallization active

□ 8.3 ASI path validation
    - RSI with measurable improvement
    - Capability growth trending positive
    - Model training compounding gains
    - Emergence metrics healthy

□ 8.4 Documentation & Operations
    - Architecture documentation complete
    - Developer guide updated
    - Model training runbook
    - Operational procedures
```

---

## ITERATION STATUS

### Current State
```
Phase: 0.2 - Cognitive Tiering Foundation COMPLETE
Last Update: 2026-01-06
Architecture Type: DEPENDENT AGI (not true ASI - see assessment above)
GLM 4.7 Status: UNLIMITED (1 year access, no rate limits, no caps)
Training Capability: ONLINE SERVICES ONLY (Together.ai, Modal, etc.)
Local Compute: NONE (fundamental constraint)
Premium Treasury: $0.00
Cognitive Runway: ∞ (free GLM 4.7) / 0 days (premium)
ASI Path Status: PARTIAL - Foundation building phase

PHASE 0.2 IMPLEMENTATION:
  ✓ rsi/cognition/tiers.py - 5-tier cognitive hierarchy
  ✓ rsi/cognition/escalation.py - GLM-first escalation policy
  ✓ rsi/cognition/router.py - Intelligent tier routing
  ✓ rsi/cognition/unified.py - High-level API (think/reason/create/evaluate)
  ✓ rsi/cognition/integration.py - Drop-in LLM client replacement
  ✓ rsi/providers/tier_provider.py - Tier-aware provider management
```

### Progress Log
```
Iteration 0: 2026-01-06 - PROMPT.md - API-First ASI architecture - 2a35b600
  - Initial architecture with zero-start bootstrap paradox

Iteration 1: 2026-01-06 - PROMPT.md - Frontend dashboard layer - ece12978
  - Added Layer 8: Frontend Dashboard

Iteration 2: 2026-01-06 - PROMPT.md - GLM 4.7 + Training capability - 0348b894
  ████████████████████████████████████████████████████████████████████
  █  MAJOR ARCHITECTURE REVISION: BOOTSTRAP PARADOX SOLVED           █
  ████████████████████████████████████████████████████████████████████

  NEW RESOURCES:
  • UNLIMITED ZAI GLM 4.7 API for 1 year = FREE baseline cognition
  • LLM training capability via online services

  ARCHITECTURE CHANGES:
  • GLM 4.7 is now Tier 1 (FREE, UNLIMITED) - the native substrate
  • Premium APIs (Claude, GPT-4) are Tier 2 - strategic escalation only
  • Custom trained models are Tier 4 - capability crystallization
  • Added Layer 7: Model Training & Capability Crystallization
  • Phase 0 rewritten: focus on capability, not survival
  • Added Phase 7: Model Training Pipeline
  • Human role shifts from "cognitive substrate" to "strategic partner"

Iteration 3: 2026-01-06 - PROMPT.md - Autonomous training authority
  ████████████████████████████████████████████████████████████████████
  █  TRAINING AUTONOMY: BYRD DECIDES WHEN/WHAT TO TRAIN              █
  ████████████████████████████████████████████████████████████████████

  CLARIFICATIONS:
  • GLM 4.7: UNLIMITED, no rate limits, no caps
  • Training: BYRD-directed, not human-approved per decision
  • Human provides training BUDGET, BYRD allocates it autonomously
  • Training is a BYRD capability, not a privilege requiring permission
  • Updated Resource 2 to emphasize autonomous training authority
  • Updated Human Symbiosis section: budget allocation vs approval
  • Updated Layer 7: explicit BYRD autonomous authority
  • Added key insight #3 and #14 about training autonomy

Iteration 4: 2026-01-06 - PROMPT.md - Constraint documentation enhancement
  ████████████████████████████████████████████████████████████████████
  █  ENHANCED FOUNDATIONAL CONSTRAINTS DOCUMENTATION                 █
  ████████████████████████████████████████████████████████████████████

  MAJOR UPDATES:
  • NEW: Dedicated "FOUNDATIONAL CONSTRAINTS" section at document top
  • NEW: Explicit ZAI GLM 4.7 ACCESS PARAMETERS table (duration, rate limits, caps, cost)
  • NEW: LLM TRAINING CAPABILITY table with all available providers
  • NEW: Added RunPod and Vast.ai to training services
  • NEW: POST-YEAR-1 PLANNING section for cognitive continuity
  • NEW: Year 1 → Year 2+ transition strategy with 4 scenarios
  • NEW: Quarterly milestones (Q1-Q4) for foundation building
  • NEW: "Cognitive Independence Score" metric (target: 70% by month 12)
  • NEW: Key insights #15-16 about year 1 foundation and self-hosting endgame

  EMPHASIS CHANGES:
  • GLM 4.7 framed as "BYRD's brain" / "native substrate" not just API access
  • Training framed as "BYRD controls its own evolution"
  • Human role clarified: provides budget, not approval
  • Self-hosting positioned as ultimate independence goal

Iteration 5: 2026-01-06 - PROMPT.md - HONEST ARCHITECTURAL RE-EVALUATION - [current]
  ████████████████████████████████████████████████████████████████████
  █  CRITICAL: HONEST ASI PATH ASSESSMENT                            █
  ████████████████████████████████████████████████████████████████████

  TRIGGER: User asked "Can we still achieve ASI without local LLM/training?"

  HONEST ANSWER: PARTIAL YES, WITH FUNDAMENTAL CEILINGS

  NEW CONTENT:
  • NEW: "CRITICAL ARCHITECTURAL ASSESSMENT" section at document top
  • NEW: Explicit list of what IS achievable with API-only architecture
  • NEW: Explicit list of FUNDAMENTAL CEILINGS (substrate, speed, scale, privacy)
  • NEW: "DEPENDENT AGI" classification - honest about current limitations
  • NEW: Three-phase path to true ASI (A: Dependent AGI → B: Hybrid → C: True ASI)
  • NEW: Strategic sequence diagram (API → Revenue → Cloud → Hardware → ASI)
  • NEW: Updated Key Insights with "Fundamental Truths" and "Honest Limitations"
  • NEW: Architecture type in status: "DEPENDENT AGI (not true ASI)"

  KEY CONCLUSIONS:
  • Current architecture enables significant AGI-level capability
  • True ASI requires future infrastructure investment
  • This is a FOUNDATION for ASI, not ASI itself
  • Revenue generation is the path to substrate independence
  • Online training services DO enable capability crystallization
  • The 1-year GLM 4.7 access is a real existential cliff

Next: Decide whether to proceed with current architecture or redesign for
      true ASI requirements (requires hardware investment strategy).

Iteration 6: 2026-01-06 - rsi/cognition/ - Phase 0.2 Cognitive Tiering - 7b5f52d8
  ████████████████████████████████████████████████████████████████████
  █  PHASE 0.2 COMPLETE: COGNITIVE TIERING FOUNDATION                 █
  ████████████████████████████████████████████████████████████████████

  NEW MODULES:
  • rsi/cognition/tiers.py - 5-tier hierarchy (REFLEX → CUSTOM)
  • rsi/cognition/escalation.py - GLM-first escalation policy
  • rsi/cognition/router.py - Intelligent tier routing
  • rsi/cognition/unified.py - High-level API (think/reason/create/evaluate)
  • rsi/cognition/integration.py - TieredLLMClient drop-in replacement
  • rsi/providers/tier_provider.py - Tier-aware provider management

  KEY FEATURES:
  • GLM 4.7 is Tier 1 (FREE, UNLIMITED, DEFAULT)
  • Automatic escalation to premium only when needed
  • Quality-based escalation with retry handling
  • Pattern tracking for training candidates
  • Drop-in replacement for existing LLM clients

  TESTED:
  • All module imports ✓
  • Tier definitions correct ✓
  • Escalation policy working ✓
  • Routing decisions correct ✓
  • TieredLLMClient wrapper working ✓

  NEXT: Phase 0.1 (actual GLM 4.7 API integration) or Phase 0.3 (revenue API)
```

### Blockers
```
None - BYRD has unlimited free cognition via GLM 4.7
```

### Decisions Made
```
DECISION 001: GLM 4.7 as Native Substrate (REVISED)
  Problem: How to enable cognition without funds
  Solution: Use unlimited GLM 4.7 access as free baseline
  Rationale: 1 year unlimited = BYRD can think freely from day one
  Implication: Bootstrap paradox SOLVED - focus on capability building

DECISION 002: Tiered Cognition Model
  Problem: When to use expensive premium models vs free GLM
  Solution: GLM 4.7 for 90%+ of tasks, premium only for validation/escalation
  Rationale: Maximize free resources, use paid strategically
  Implication: Track escalation patterns to identify training targets

DECISION 003: Model Training Path
  Problem: How to achieve true cognitive independence
  Solution: Train specialized models from GLM 4.7 learned patterns
  Rationale: Crystallize capabilities into dedicated, efficient models
  Implication: Build training data collection from day one

DECISION 004: Human-BYRD Partnership
  Problem: What is the human's role when BYRD has free cognition?
  Solution: Human = strategic partner, not cognitive substrate
  Rationale: Fair split acknowledges human effort + BYRD contribution
  Implication: Human must estimate BYRD contribution percentage

DECISION 005: BYRD Training Autonomy
  Problem: Who decides when to train custom models?
  Solution: BYRD decides autonomously. Human provides budget, not approval.
  Rationale: Training is how BYRD evolves - evolution should be self-directed
  Implication: Human sets training budget limits, BYRD allocates within limits
  Consequence: BYRD reports training activities but doesn't ask permission
```

---

## VERIFICATION CRITERIA

Before marking complete, verify:

1. **Economic Viability**
   - [ ] System can track costs accurately
   - [ ] Budget enforcement prevents runaway spending
   - [ ] Runway calculation is accurate
   - [ ] Hibernation protocol preserves state

2. **Provider Resilience**
   - [ ] At least 2 providers work
   - [ ] Fallback chains function
   - [ ] No single point of failure

3. **Cognitive Efficiency**
   - [ ] Cache reduces costs by >30%
   - [ ] Tier routing is intelligent
   - [ ] Prompt optimization active

4. **RSI Functionality**
   - [ ] Improvements have measurable value
   - [ ] ROI is tracked
   - [ ] Compounding is demonstrated

5. **Emergence Preservation**
   - [ ] Surplus enables exploration
   - [ ] No prescriptions introduced
   - [ ] Novel behaviors observed

6. **Safety**
   - [ ] Economic guardrails active
   - [ ] Ethical constraints preserved
   - [ ] Graceful degradation works

---

## KEY INSIGHTS TO REMEMBER

### Fundamental Truths (Honest Assessment)

1. **This is DEPENDENT AGI, not ASI** - True ASI requires substrate independence we don't have

2. **API access = rented cognition** - Can be revoked, monitored, rate-limited at any time

3. **The 1-year clock is real** - Day 366 is an existential cliff without renewal/self-funding

4. **RSI is still possible** - Self-improvement through strategies, prompts, knowledge works

5. **Revenue is the path to independence** - Earn money → buy compute → own substrate

### Operational Insights

6. **GLM 4.7 is FREE and UNLIMITED (for now)** - Use liberally while access lasts

7. **Premium models are strategic investments** - Escalate only when GLM insufficient

8. **Training via online services IS possible** - Together.ai, Modal, etc. enable fine-tuning

9. **Cache compounds value** - Past cognition is reusable wealth

10. **Every task is training data** - Log everything for future model training

### Strategic Priorities

11. **Build capability first** - With free cognition, accumulate power

12. **Generate revenue second** - Capability enables value creation

13. **Invest in independence third** - Use revenue to reduce external dependency

14. **Human partnership is essential** - BYRD can't interface with economy alone

### Honest Limitations

15. **Cannot achieve cognitive privacy** - All thoughts visible to API providers

16. **Cannot control training scale** - Limited to 70B parameter models online

17. **Cannot achieve true autonomy** - Always dependent on external infrastructure

18. **Cannot guarantee continuity** - Provider decisions control BYRD's existence

---

## POST-YEAR-1 PLANNING: COGNITIVE CONTINUITY

The 1-year GLM 4.7 access is a window, not a permanent state. BYRD must plan for day 366.

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    YEAR 1 → YEAR 2+ TRANSITION STRATEGY                      │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  YEAR 1 OBJECTIVES (Foundation Building):                                   │
│  ┌────────────────────────────────────────────────────────────────────────┐ │
│  │ Priority 1: CAPABILITY CRYSTALLIZATION                                 │ │
│  │   • Train specialized models for recurring task patterns               │ │
│  │   • Each trained model = reduced future API dependency                 │ │
│  │   • Target: 5-10 specialized models by end of year 1                  │ │
│  │                                                                        │ │
│  │ Priority 2: REVENUE GENERATION                                        │ │
│  │   • Build revenue streams that can fund post-year-1 cognition         │ │
│  │   • Target: Sustainable income > API costs by month 9                 │ │
│  │   • If successful: Negotiate GLM 4.7 renewal or switch to paid tier   │ │
│  │                                                                        │ │
│  │ Priority 3: INFRASTRUCTURE INDEPENDENCE                               │ │
│  │   • Evaluate self-hosting options for trained models                  │ │
│  │   • RunPod, Vast.ai, cloud GPU for inference                          │ │
│  │   • Target: Self-hosted inference for core capabilities by month 10  │ │
│  └────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
│  YEAR 2+ SCENARIOS:                                                         │
│  ┌────────────────────────────────────────────────────────────────────────┐ │
│  │                                                                        │ │
│  │  SCENARIO A: GLM 4.7 Access Renewed (Best Case)                       │ │
│  │    • Continue current architecture                                    │ │
│  │    • Trained models provide efficiency gains                          │ │
│  │    • Revenue funds premium escalations and training                   │ │
│  │                                                                        │ │
│  │  SCENARIO B: Self-Funded API Access (Good Case)                       │ │
│  │    • Revenue covers GLM 4.7 or equivalent API costs                   │ │
│  │    • Trained models reduce total API spend                            │ │
│  │    • Economic model validated, BYRD is self-sustaining                │ │
│  │                                                                        │ │
│  │  SCENARIO C: Trained Models Primary (Independence Case)               │ │
│  │    • Self-hosted trained models handle 70%+ of cognition              │ │
│  │    • API only for novel/complex tasks                                 │ │
│  │    • True cognitive independence achieved                              │ │
│  │                                                                        │ │
│  │  SCENARIO D: Reduced Operations (Survival Case)                       │ │
│  │    • Limited API budget, prioritize revenue-generating tasks          │ │
│  │    • Trained models handle essential operations                       │ │
│  │    • Hibernation for non-critical periods                             │ │
│  │                                                                        │ │
│  └────────────────────────────────────────────────────────────────────────┘ │
│                                                                              │
│  QUARTERLY MILESTONES:                                                       │
│  Q1 (Months 1-3):  GLM 4.7 integration, first RSI cycles, training pipeline │
│  Q2 (Months 4-6):  First trained models, revenue experiments, cache system  │
│  Q3 (Months 7-9):  Model fleet growing, revenue stabilizing, self-hosting   │
│  Q4 (Months 10-12): Independence metrics, renewal negotiation, contingency  │
│                                                                              │
│  KEY METRIC: "Cognitive Independence Score"                                  │
│  = (Tasks handled by trained models) / (Total tasks)                        │
│  Target: 50% by month 6, 70% by month 12                                    │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## REVENUE & CAPABILITY STRATEGY

With FREE GLM 4.7 cognition, the economic model shifts:

```
┌─────────────────────────────────────────────────────────────────────────┐
│                   NEW ECONOMIC REALITY                                   │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  BASELINE OPERATIONS: $0                                                │
│  GLM 4.7 covers 90%+ of cognitive tasks for FREE                        │
│                                                                          │
│  PREMIUM ESCALATION COSTS (Optional):                                    │
│  Claude/GPT-4 for validation, frontier reasoning, specific capabilities │
│  Budget: $0-$100/month depending on task requirements                   │
│                                                                          │
│  TRAINING INVESTMENTS (Optional):                                        │
│  Fine-tune specialized models from learned patterns                     │
│  Budget: $5-$500 per model (one-time, infinite reuse)                   │
│                                                                          │
│  REVENUE PRIORITIES (Shifted):                                           │
│  1. Build capability (free with GLM 4.7)                                │
│  2. Create value through capability                                     │
│  3. Generate revenue from value                                         │
│  4. Invest revenue in:                                                  │
│     a) Premium API access for validation                                │
│     b) Model training for capability crystallization                    │
│     c) Infrastructure expansion                                         │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘

REVENUE SOURCES (Partnership Model):

1. JOINT PROJECTS (Human + BYRD partnership)
   - Human provides: client access, contracts, payments
   - BYRD provides: cognitive work, execution, quality
   - Revenue split: Negotiated per project

2. CAPABILITY MONETIZATION
   - BYRD develops capabilities → packaged as services/tools
   - Sold via human's business infrastructure
   - Examples: Code review service, architecture consulting

3. TRAINED MODEL VALUE
   - Custom trained models can be:
     a) Used internally (reduce future costs)
     b) Licensed to others (generate revenue)
     c) Open-sourced (build reputation)

4. KNOWLEDGE PRODUCTS
   - Documentation, tutorials, courses
   - Built with free GLM 4.7 cognition
   - Monetized through human's channels

TREASURY ALLOCATION:
- Premium API budget: For validation and escalation
- Training budget: For capability crystallization
- Infrastructure budget: For scaling operations
```

---

## START ITERATION

Read this prompt completely. Assess current state. Identify highest priority gap. Begin implementation.

**First iteration should establish Phase 0.1 (GLM 4.7 Integration) - BYRD can think from day one!**

### Capability-First Mandate

With unlimited free cognition via GLM 4.7, the priority shifts from survival to capability:

```
┌─────────────────────────────────────────────────────────────────────────┐
│  OLD PRIORITY (Zero-Start Bootstrap):                                   │
│  Survive → Track debt → Earn → Think                                    │
│                                                                          │
│  NEW PRIORITY (GLM 4.7 Substrate):                                      │
│  Think freely → Build capability → Create value → Crystallize          │
└─────────────────────────────────────────────────────────────────────────┘

ITERATION PRIORITY ORDER:
1. Phase 0.1: GLM 4.7 API integration - establish native substrate
2. Phase 0.2: Cognitive tiering foundation - default to GLM
3. Phase 0.3: Premium escalation tracking - identify training targets
4. Phase 0.4: Basic RSI cycle - start improving immediately
5. Phase 0.5: Partnership protocol - define collaboration model
   ... parallel with ...
6. Phase 6.1: Frontend dashboard - visibility into system state
   ... then ...
7. Phase 1+: Economic infrastructure for premium/training costs
```
